{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69ef6aad",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "In this first lesson by Karpathy we go through a step-by-step explanation of backpropagation and training of neural networks by building a **micrograd** engine. The notebooks should be followed in numbered order.\n",
    "\n",
    "Link to lesson: https://www.youtube.com/watch?v=VMj-3S1tku0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd97ae4a",
   "metadata": {},
   "source": [
    "# What is Micrograd?\n",
    "Micrograd is an engine for automatically evaluating the gradient of your loss function with respect to the weight of your neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59eabce",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2de9d323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting micrograd\n",
      "  Downloading micrograd-0.1.0-py3-none-any.whl (4.9 kB)\n",
      "Installing collected packages: micrograd\n",
      "Successfully installed micrograd-0.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install micrograd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142d8006",
   "metadata": {},
   "source": [
    "### Math Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16d9844f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from micrograd.engine import Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2dddf8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating two Values\n",
    "a = Value(-4.0)\n",
    "b = Value(2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "344e1a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value(data=-2.0, grad=0)\n",
      "Value(data=0.0, grad=0)\n",
      "Value(data=-3.0, grad=0)\n",
      "Value(data=-1.0, grad=0)\n"
     ]
    }
   ],
   "source": [
    "# Doing common math operations\n",
    "c = a + b;print(c)\n",
    "d = a * b + b ** 3;print(d)\n",
    "c += c + 1;print(c)\n",
    "c += 1 + c + (-a);print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "655ceeeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value(data=0.0, grad=0)\n",
      "Value(data=6.0, grad=0)\n"
     ]
    }
   ],
   "source": [
    "# Using relu to squash negative values to zero\n",
    "d += d * 2 + (b + a).relu();print(d)\n",
    "d += 3 * d + (b - a).relu();print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6106ec83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value(data=-7.0, grad=0)\n",
      "Value(data=49.0, grad=0)\n",
      "Value(data=24.5, grad=0)\n",
      "Value(data=24.70408163265306, grad=0)\n"
     ]
    }
   ],
   "source": [
    "# Doing some more math operations\n",
    "e = c - d;print(e)\n",
    "f = e ** 2;print(f)\n",
    "g = f / 2.0;print(g)\n",
    "g += 10.0 / f;print(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3326cad9",
   "metadata": {},
   "source": [
    "### Backpropagation\n",
    "While **micrograd** can be used to create simple math operations that is not the most interesting part about the engine! Actually **micrograd** builds a tree of the relationships between the calculations, e.g. that c was calculated by adding a and b. This means that for each calculation we can get the output of the forward pass (the printed values), but also of the backwards pass, which will be demonstrated next.\n",
    "\n",
    "The value of the backwards pass is calculated using \"the chain rule\", which tells us how to find the derivative of a composite function, e.g. F(x) = f( g(x) ). The rule tells us to find the derivative of the outer function and multiply it with the derivative of the inner function as such: F'(x) = f'( g(x) ) * g'(x). This calculation is done recursively, and makes use of the hierachical **micrograd** tree. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "14077d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value(data=24.70408163265306, grad=0)\n"
     ]
    }
   ],
   "source": [
    "# The output of the forward pass for g\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4128cc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating all gradients (backpropagation)\n",
    "g.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f11bf749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value(data=-4.0, grad=138.83381924198252)\n",
      "Value(data=2.0, grad=645.5772594752186)\n",
      "Value(data=-1.0, grad=-6.941690962099126)\n",
      "Value(data=6.0, grad=6.941690962099126)\n",
      "Value(data=49.0, grad=0.4958350687213661)\n",
      "Value(data=24.70408163265306, grad=1)\n"
     ]
    }
   ],
   "source": [
    "# Getting all the gradients\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)\n",
    "print(d)\n",
    "print(f)\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86408999",
   "metadata": {},
   "source": [
    "These gradients tell us how the values of a and b affect the function g through the mathematical expression. That is how an increase/decrease of a and b affect the output of g."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
